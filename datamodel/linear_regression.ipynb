{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9fb722-a7e8-4846-83e9-df31653fbbe9",
   "metadata": {},
   "source": [
    "# Simple Example of Data Analysis - Linear Projection\n",
    "\n",
    "See, e.g. \n",
    "\n",
    "- https://en.wikipedia.org/wiki/Linear_least_squares\n",
    "- https://en.wikipedia.org/wiki/Ordinary_least_squares\n",
    "- https://en.wikipedia.org/wiki/Data_analysis\n",
    "- https://en.wikipedia.org/wiki/Projection_(linear_algebra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3abcc34b-4dec-44d5-9c03-ae0c8d083c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Jupyter core packages...\n",
      "IPython          : 8.11.0\n",
      "ipykernel        : 6.21.3\n",
      "ipywidgets       : 8.0.4\n",
      "jupyter_client   : 8.0.3\n",
      "jupyter_core     : 5.2.0\n",
      "jupyter_server   : 2.4.0\n",
      "jupyterlab       : 3.6.1\n",
      "nbclient         : 0.7.2\n",
      "nbconvert        : 7.2.9\n",
      "nbformat         : 5.7.3\n",
      "notebook         : 6.5.3\n",
      "qtconsole        : 5.4.0\n",
      "traitlets        : 5.9.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('3.10.6', '1.24.2')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as al\n",
    "from matplotlib import pyplot as plt\n",
    "from platform import python_version\n",
    "\n",
    "!jupyter --version\n",
    "(python_version(), np.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a59590a-147e-4b84-a478-8b28092c5bf3",
   "metadata": {},
   "source": [
    "## Linear Algebra with real estate as an example\n",
    "This is just a \"thought experiment\" - all the data is randomly generated.\n",
    "\n",
    "Let's say that a house price is determined by just 3 *factors* (features):\n",
    "\n",
    "1. Distance $D$ in miles from the City center, for example 20\n",
    "2. House condition, $C$, for example 50 (on a scale from 0 to 100)\n",
    "3. Number of rooms, $R$, for example 3\n",
    "\n",
    "We want to find a *function* (rule) that estimates a house price $P$ based on just these three factors.\n",
    "The simplest case would be a *linear function*:\n",
    "\n",
    "\\begin{align}\n",
    "P = A + D * \\text{\"distance from the city\"} + C * \\text{\"house condition\"} + R *\\text{\"number of rooms\"}  \\label{estimate}\\tag{0}\n",
    "\\end{align}\n",
    "\n",
    "where the meaning of fixed numbers $A, D,C,R$ is as follows:\n",
    "- $A$ is a constant, measuring something that affects all houses in the same way (e.g. market trend)\n",
    "- $D$ is a location *effect* on price\n",
    "- $C$ is a house condition effect on price\n",
    "- $R$ is a number of rooms effect on proce\n",
    "\n",
    "We have just described a notion of *linear model*, cf, https://en.wikipedia.org/wiki/Linear_model\n",
    "\n",
    "Last year house sales database might contain a *table*\n",
    "\n",
    "\n",
    "| distance | condition | number of rooms | price |\n",
    "|:---------|:---------:|----------------:|:------|\n",
    "| 20       |     5     |               3 |200|\n",
    "| 10       |     8     |               4 |500|\n",
    "|..........|...........|.................|...|\n",
    "\n",
    "Can we use this table to determine the numbers $A, D,C,R$?\n",
    "Here is where *Linear Algebra* comes in. Suppose we have this data for $100$ houses.\n",
    "Hence, there are three $n$-dimensional (column) *vectors* of length (dimension) n = 100\n",
    "for each of the features and there is the fourth $n$-dimensional vector of  house prices.\n",
    "\n",
    "Plausible data for all four feature vectors is randomly generated. \n",
    "This data can be (re)generated any number of times - to view a summary see <a href='#histograms'>histograms</a>  after data generation step below.  \n",
    "\n",
    "It is important to note at this point that our real estate data for 100 houses\n",
    "is *represented* by four factor (feature) vectors in 100-dimensional *vector space*.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3288cdf-6048-4be3-a5c4-f8401a0bb263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean = 500\n",
    "std = 100\n",
    "n_houses = 100\n",
    "n = n_houses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "205eb85a-df92-47fe-a9c5-720396b89cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def number_of_rooms( price ) :\n",
    "\n",
    "    if price < mean - 2 * std :\n",
    "         return np.random.randint( 1,2 )\n",
    "\n",
    "    if price < mean - 1 :\n",
    "         return np.random.randint( 2,3 )\n",
    "\n",
    "    if price > mean + 2 * std :\n",
    "         return np.random.randint( 5,6)\n",
    "\n",
    "    if price > mean + 1 * std :\n",
    "         return np.random.randint( 4,5 )\n",
    "\n",
    "    return np.random.randint( 3,4 )\n",
    "    \n",
    "n_rooms = np.vectorize( number_of_rooms ) \n",
    "\n",
    "\n",
    "def house_condition( price ) :\n",
    "    if price < mean - 2 * std :\n",
    "         return np.random.normal(loc=20, scale=2, size=1 )[0]\n",
    "\n",
    "    if price < mean -1 :\n",
    "         return np.random.normal(loc=30, scale=3, size=1 )[0]\n",
    "\n",
    "    if price > mean + 2 * std :\n",
    "         return np.random.normal(loc=80, scale=8, size=1 )[0]\n",
    "\n",
    "    if price > mean + 1 * std :\n",
    "         return np.random.normal(loc=60, scale=6, size=1 )[0]\n",
    "\n",
    "    return np.random.normal(loc=50, scale=5, size=1 )[0]\n",
    "  \n",
    "h_condition =  np.vectorize( house_condition) \n",
    "\n",
    "\n",
    "def house_distance_from_the_city_center( price ) :\n",
    "    if price < mean - 2 * std :\n",
    "        return np.random.normal(loc=25, scale=2.5, size=1 )[0]\n",
    "    \n",
    "    if price < mean - 1 * std :\n",
    "        return np.random.normal(loc=20, scale=2, size=1 )[0]\n",
    "    \n",
    "    if price > mean + 2 * std :\n",
    "        return np.random.normal(loc=5, scale=.5, size=1 )[0]\n",
    "    \n",
    "    if price > mean + 1 * std :\n",
    "        return np.random.normal(loc=10, scale=1, size=1 )[0]\n",
    "\n",
    "    return np.random.normal(loc=15, scale=1.5, size=1 )[0]\n",
    "  \n",
    "h_distance = np.vectorize( house_distance_from_the_city_center )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56abd9c1-ee09-402f-abe5-13661654d07c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <a id=\"histograms\">  Data *Histograms* </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11af053a-e3e4-48e8-a777-7d749137e990",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "price_in_thousands = np.random.normal(loc=mean, scale=std, size=n )\n",
    "distance = h_distance(price_in_thousands)\n",
    "condition = h_condition( price_in_thousands  )\n",
    "rooms = n_rooms( price_in_thousands )\n",
    "\n",
    "#print( np.cov(np.ones(100), rooms ))\n",
    "\n",
    "#  uncomment to see a histogram\n",
    "\n",
    "plt.hist(price_in_thousands)\n",
    "#plt.hist( rooms )\n",
    "#plt.hist( condition )\n",
    "#plt.hist( distance )\n",
    "# function to show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247d5e30",
   "metadata": {},
   "source": [
    "### [Linear Vector Space](https://en.wikipedia.org/wiki/Vector_space)\n",
    "\n",
    "Let $ v_1, v_2, \\cdots, v_k  $ be $k$ fixed ($n$-dimensional) vectors in our $n$-dimensional (e.g. $n = 100, k = 4 $) vector  space $V$.\n",
    "For any real numbers  $  \\alpha_1, \\alpha_2, \\cdots,  \\alpha_k $ we have a *linear combination*\n",
    "\n",
    "\\begin{align}\n",
    "v = \\alpha_1 v_1 + \\alpha_2 v_2 + \\cdots + \\alpha_k v_k \\in L \\subset V \\label{eq1}\\tag{1}\n",
    "\\end{align}\n",
    "\n",
    "The formula (\\ref{eq1}) represents a linear mixture of $k$ feature vectors.\n",
    "The set $L$ of all such linear combinations is a $k$-dimensional ($k$-parameter) *subspace* of $V $.\n",
    "Suppose now that we have some other vector $v_0 \\in V $.\n",
    "It might belong to $L$, i.e. it could happen\n",
    "that $ v_0 = \\beta_1 v_1 + \\beta_2 v_2 + \\cdots v_3 + \\beta_k v_k$, for some real numbers $ \\beta_1, \\; \\beta_2 , \\; \\cdots , \\; \\beta_k $\n",
    "or it might not. In any case, we can try to solve the following problem\n",
    "> Find an *orthogonal projection* $ w_0 \\in L $ of the vector $v_0$ onto the vector space $L$\n",
    ">\n",
    "> In other words, find  $w_0 \\in L $ such that the length  ($=$ Euclidean *norm*)\n",
    "> of vector $ w_0 - v_0 $  is no greater than the length of  $ w - v_0 $ for any $ w \\in L $\n",
    ">\n",
    "> In other words, we have an *optimization* problem (cf. https://en.wikipedia.org/wiki/Mathematical_optimization):\n",
    "\n",
    "> find real numbers $ x_1,x_2, \\cdots, x_k $ that minimize the norm\n",
    "\n",
    "\\begin{equation}\n",
    "\\parallel x_1 v_1 + x_2 v_2 + \\cdots + x_k v_k - v_0  \\parallel  \\label{eq2}\\tag{2}\n",
    "\\end{equation}\n",
    ">\n",
    "> **Interpretation**:  we are looking for  $4$ *coefficients*   that can be used   to  estimate a price of every house as a mixture ([0](#mjx-eqn-estimate))\n",
    "> of house features in a \"best way possible\" (well, in some Linear Algebra sense)\n",
    ">\n",
    "\n",
    "To solve this problem, we introduce\n",
    "(collect) an  $ n \\times k $ *matrix* $ M $ in such a way that $k$ columns of $M$ are exactly our $k$\n",
    "(feature) vectors $ v_1, v_2, \\cdots, v_k$ (in that order).\n",
    "\n",
    "Scanning the matrix $M$ row by row we see that:\n",
    "\n",
    "- the first row of M is a $k$-dimensional vector ( the first coordinate ov $v_1$, the first coordinate ov $v_2, \\cdots$ )\n",
    "- the second row of M is formed by the second coordinate ov $v_1$, the second coordinate ov $v_2, \\cdots $\n",
    "- the third row of M is formed by the third coordinate ov $v_1$, the third coordinate ov $v_2, \\cdots$\n",
    "\n",
    "and so on. In case of original real estate problem ([0](#mjx-eqn-estimate)), it is useful to think that a row numeber $i$  of $M$ is\n",
    "a $k$-dimensional vector of the features of the house number $i$.\n",
    "\n",
    "In this notation we can rewrite our minimization problem ($\\ref{eq2}$) as\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\text{find a vector } x = (x_1,x_2, \\cdots, x_k)  \\text{ that minimizes norm (distance) } objective \\; function   \\parallel Mx - v_0 \\; \\parallel  \\label{eq3}\\tag{3}\n",
    "\\end{align}\n",
    "\n",
    "The expression  (\\ref{eq3}) can be read as follows. We have $n \\times k$ matrix $M$ times $k$-vector $x$. The result will be $n$-vector that is\n",
    "a linear combination of the columns of $M$. Since $k$ coordinates of $x$ are unknown variables, $Mx$ essentially represents a generic vector in $L$\n",
    "as in (\\ref{eq1}). Hence, the objective function (\\ref{eq3}) represents the *distance* of $v_0$ from a generic vector in $L$.\n",
    "\n",
    "Denote the *dot product* (https://en.wikipedia.org/wiki/Dot_product) of vectors $a,b$ by $<a,b>$.\n",
    "By definition,   $w$ is an orthogonal projection of $v_0$ onto $L$ if and only if  the vector $ w - v_0 $ is *perependicular* to $L$, that is\n",
    "if and only if $ <w - v_0, y> \\;=\\; 0 \\;$  for any $y \\in L $.\n",
    "Since $L$ is a *linear span* of the columns $v_i, i = 1,\\; \\cdots. \\; k $ of the matrix $M$,\n",
    "this requirement leads to a system of so-called *normal* equations\n",
    "\n",
    "\\begin{align}\n",
    "    <Mx - v_0 ,\\; v_i> \\; = \\;  0 \\;  \\text{that is} \\; <Mx,\\;v_i> \\;= \\; <v_0,v_i> , \\;     i = 1,2,\\cdots, k   \\label{eq4}\\tag{4}\n",
    "\\end{align}\n",
    "\n",
    "Both sides of equatons (\\ref{eq4})  are dot products with colums of $M$, in fact\n",
    "\\begin{align}\n",
    "<Mx,v_i> = < x_1 v_1 + x_2 v_2 + \\cdots +  x_k v_k, v_i > = \\sum_{j}^k <v_i,v_j> x_j\n",
    "\\end{align}\n",
    "where  the matrix $G$ with elemnts $ <v_i,v_j>, \\; i,j = 1, \\cdots , k $ is the *Gram matrix* of the vector set $ v_1, \\cdots , v_k $ (cf. https://en.wikipedia.org/wiki/Gram_matrix) \n",
    "\n",
    "Using notation $ M^T $ for a $ k \\times n $ *transpose* of $M$, note that $ G = M^TM$ and \n",
    "rewrite $k$ equations (\\ref{eq4}) as one matrix equation,\n",
    "\n",
    "\\begin{align}\n",
    " M^TMx \\;= \\; M^Tv_0 \\label{eq5}\\tag{5}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "If the $k \\times k$ (Gram) matrix $M^TM$ is *invertible*, the equation (\\ref{eq5}) has a unique solution\n",
    "\n",
    "\\begin{align}\n",
    " x_0 \\; = \\; (M^TM)^{-1}M^Tv_0 \\; \\text{ and therefore, the projection} \\; Mx_0 \\; \\text{is equal to} \\; M(M^TM)^{-1}M^Tv_0\\;  \\label{eq6}\\tag{6}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a00e9-1b3d-4f48-9cba-41fc562b5387",
   "metadata": {},
   "source": [
    "**Remark 1.**\n",
    "We have found the  *orthogonal projection operator* onto a linear span $L$ of columns of $M$. This *linear operator* is represented\n",
    "  by the matrix $ M(M^TM)^{-1}M^T $\n",
    "\n",
    "**Remark 2.**\n",
    "The problem can be solved even when the matrix $M^TM$ is not invertible.\n",
    "This, however, could be a main theme for another story (see e.g. https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse )\n",
    "\n",
    "### Back to \"reality\"\n",
    "We would like to find four numbers $ A, D, C, R $ such that the price\n",
    "of the house number $i$ can be estimated (see ([0](#mjx-eqn-eq0)),([1](#mjx-eqn-eq1))) as a *linear combination*\n",
    "\n",
    "\\begin{align}\n",
    "\\text{ A + D * distance[i] + C * condition[i] + R * rooms[i] }      \\label{eq7}\\tag{7}\n",
    "\\end{align}\n",
    "\n",
    "Recall that\n",
    "\n",
    "- D is the linear effect of a house distance from the city center on the price\n",
    "- C is the linear effect of a house condition on the price\n",
    "- R is the linear effect of a number of rooms on the price\n",
    "\n",
    "For example, if it turns out that $A = 100, D=-2, C=20, R = 200 $ then the price of the house number 10 will be estimated as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89930f33-4580-4526-95d4-d22376993676",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.31993, 29.23659, 2, 1056.09202, 470.26964)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=100; D=-2; C=20; R = 200\n",
    "(round( distance[10],5),\n",
    " round( condition[10],5 ),\n",
    " round(rooms[10],5),\n",
    " round( A + D * distance[10] + C * condition[10] + R * rooms[10], 5),\n",
    " round( price_in_thousands[10], 5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a012e-01e9-4ea0-9cd8-b88fb97684e2",
   "metadata": {},
   "source": [
    "This estimation is way off. Moreover, we need these four coefficients to \"work\" for all houses. So, with this choice of ecoefficients, what is the estimate of the price of house number 91?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0773990-fa5b-49ec-a448-7c3e6e4c453b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.45947, 24.09654, 2, 951.01175, 443.8503)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(round( distance[91],5),\n",
    " round( condition[91],5 ),\n",
    " round(rooms[91],5),\n",
    " round( A + D * distance[91] + C * condition[91] + R * rooms[91], 5),\n",
    " round( price_in_thousands[91], 5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b772d024",
   "metadata": {},
   "source": [
    "Not good either"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfdec2d-daaf-4938-8b07-162e3ca2cbaa",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "To find an optimal estimate ([7](#mjx-eqn-eq7)) compute the four-dimensional vector $(A, D,C,R)$ by formula ([6](#mjx-eqn-eq6)).\n",
    "\n",
    "First, initialize the matrix $M$. Bear in mind, that the first column of $M$ is an $n$-dimensional vector with all its coordinates equal to $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d39a67d3-a0df-4bcb-92c3-230546d2ade0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# assign column vectors\n",
    "n_factors = 4\n",
    "M = np.zeros( ( n, n_factors) )\n",
    "M[:,0] = np.ones(n)     # v_1\n",
    "M[:,1] = distance       # v_2\n",
    "M[:,2] = condition      # v_3\n",
    "M[:,3] = rooms          # v_4\n",
    "H = price_in_thousands  # v_0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da64618",
   "metadata": {},
   "source": [
    "Invert the matrix $M^TM$ as prescribed by ([6](#mjx-eqn-eq6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbb8a829",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determinant = 6824951860.179104\n"
     ]
    }
   ],
   "source": [
    "d = np.dot( np.transpose(M), M )\n",
    "print( \"determinant =\", al.det(d) )\n",
    "inv_M = al.inv( d )\n",
    "#inv_M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208dc55",
   "metadata": {},
   "source": [
    "**Remark 3.** This is a huge number, and that is one of the reasons for the existence of better methods of finding ortogonal projections, see\n",
    "for example, https://en.wikipedia.org/wiki/Singular_value_decomposition and a section on SVD below.\n",
    "\n",
    "We are almost done. Compute $M^Tv_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8a275",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0b8d1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "B = np.dot( np.transpose(M), H )   # H == price_in_thousands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c81a17",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7464d0a",
   "metadata": {},
   "source": [
    "<a id=\"regresult\">  According to ([6](#mjx-eqn-eq6)), the unique solution to our linear regression nproblem is </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fea4a94-9a36-4721-bad2-3681e87b5e71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.dot( inv_M, B )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d9642d2-c659-42c3-a308-4a45a38c558d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([396.12751815,  -8.22714306,   1.83551716,  57.43468942])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x   # == (A, D, C, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc7da1",
   "metadata": {},
   "source": [
    "These four numbers can be used to obtain a price-estimate for any house. Certainly, we can now estimate prices of all the houses on our original 100-long list (cf. [7](#mjx-eqn-eq7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fd922bb-0db4-46ad-9244-c7f3dfb0880f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimated_prices = np.dot( M,  x )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b550a-f57d-4638-8626-35eed7218385",
   "metadata": {},
   "source": [
    "Let's compare these estimates with \"actual\" prices for the houses 10 and 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ec70b29-fef4-4aac-9cb1-d6bc98876219",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.31993, 29.23659, 2, 1056.09202, 470.26964, 446.84902)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(round( distance[10],5),\n",
    " round( condition[10],5 ),\n",
    " round(rooms[10],5),\n",
    " round( A + D * distance[10] + C * condition[10] + R * rooms[10], 5),\n",
    " round( price_in_thousands[10], 5 ),\n",
    " round( estimated_prices[10], 5 )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5a3b348-1f93-42ee-9fdb-f40dddcd9eb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.45947, 24.09654, 2, 951.01175, 443.8503, 428.0392)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(round( distance[91],5),\n",
    " round( condition[91],5 ),\n",
    " round(rooms[91],5),\n",
    " round( A + D * distance[91] + C * condition[91] + R * rooms[91], 5),\n",
    " round( price_in_thousands[91], 5 ),\n",
    " round( estimated_prices[91], 5 )  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9a8ff-4784-406e-aaee-df754fe70bd7",
   "metadata": {},
   "source": [
    "This is much better estimate than the original random choice of coefficients.\n",
    "To have a feel for how far away is the linear projection from original\n",
    "price vector, compute the Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f743ecb7-0f08-4df8-94de-eea1b5ef0835",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329.9491421210833"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al.norm( estimated_prices - price_in_thousands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d38f94-6707-43a5-af82-43b8e83e4fd0",
   "metadata": {},
   "source": [
    "Other popular measures of the approximation error are\n",
    "- average squared difference in price between estimated and original, cf. https://en.wikipedia.org/wiki/Mean_squared_error\n",
    "- average absolute value of the diffrence between estimated and original, cf.  https://en.wikipedia.org/wiki/Mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42a4bcc9-baac-48e5-a0b4-ce179debeca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1088.6643638643884, 26.551610637777088)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = (1/n) * al.norm( estimated_prices - price_in_thousands) ** 2 \n",
    "MAE = (1/n) * al.norm( estimated_prices - price_in_thousands, 1 )\n",
    "\n",
    "(MSE,MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdad54",
   "metadata": {},
   "source": [
    "Now let's make a price estimate (forecast) for a house that is not in our original 100-item list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "405a284f-0b66-4a12-bc27-b2979b98b9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577.9360140316958"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot( np.array( [1, 10, 50, 3] ), x )  # D == 20, C == 50, R == 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d6ea29",
   "metadata": {},
   "source": [
    "Being linear, the model has obvious limitations...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "909eb03c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-154.08961755899213"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot( np.array( [1, 159, 100, 10] ), x )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9dfbdf",
   "metadata": {},
   "source": [
    "### Algebra again\n",
    "\n",
    "Direct computation of the matrix $M^TM$ can result in (arrays of) very large numbers (cf. Remark 3), especially when at least one of\n",
    "the matrix dimensions is large. There is a better way to compute orthogonal projection. The important Numerical  Linear Algebra algorithm that we will\n",
    "now describe is called\n",
    "\n",
    "### [Singular Value Decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition)\n",
    "\n",
    "- A matrix $ D $ is called *diagonal* if all its elements ouside the main diagonal (all $D_{ij}$ with $i \\neq j$) are equal to zero\n",
    "- As an example, a square $n\\times n$ diagonal matrix $I_n$ such that all its diagonal elements are equal to $1$ is called *unity matrix*\n",
    "- A  square ($n \\times n$) matrix $ Q $ is called *orthogonal* if $ Q^T = Q^{-1} \\Rightarrow Q^TQ \\; = \\; 1_n\\;  = \\; QQ^T $\n",
    "- If $ n \\geq k $, an $n \\times k $-matrix $Q$ is called column-orthogonal if $ Q^TQ = 1_k $\n",
    "\n",
    "\n",
    "Let $\\; n \\geq k  $. For any $n\\times k$ matrix $A$ there are :\n",
    "- $n\\times k$ column orthogonal matrix $U$\n",
    "- $k\\times k$ orthogonal matrix $V$\n",
    "- diagonal $k \\times k $ matrix $S$ with non-negative entries\n",
    "\n",
    "such that\n",
    "\n",
    "\\begin{equation}\n",
    " A = U \\; S \\; V \\;  \\label{svd}\\tag{8}\n",
    "\\end{equation}\n",
    "\n",
    "The factorization (8) is called *Singular Value Decomposition (SVD)*, and diagonal entries of $S$ are called *singular values* of $A$\n",
    "\n",
    "Let's use SVD to compute the orthogonal projection ([6](#mjx-eqn-eq6))\n",
    "\n",
    "If the SVD of our $n \\times k $ *tall data matrix* $ M = Q_1 \\; \\Sigma_k  \\; Q_2 $ is available, we can transform ([6](#mjx-eqn-eq6)) as follows\n",
    "\n",
    "\\begin{eqnarray}\n",
    "x_0 \\; = \\; (M^TM)^{-1}M^Tv_0 \\; = \\; (Q^{T}_2 \\; \\Sigma_k \\; Q^{T}_1 \\; Q_1 \\; \\Sigma_k Q_2 )^{-1} \\; Q^{T}_2 \\; \\Sigma_k \\; Q^{T}_1 \\; v_0 \\; = \\\\ =  \n",
    " \\; (Q^{T}_2 \\; \\Sigma_k \\; I_k \\; \\Sigma_k Q_2 )^{-1} \\; Q^{T}_2 \\; \\Sigma_k Q^{T}_1 \\; v_0 \\;   = \\;   Q^{T}_2 \\; \\Sigma^{-2}_k \\; Q_2 \\;  Q^{T}_2 \\; \\Sigma_k \\; Q^{T}_1 \\; v_0 \\; = \\; Q^{T}_2 \\; \\Sigma^{-1}_k \\; Q^{T}_1\n",
    "\\end{eqnarray}\n",
    "\n",
    "and therefore\n",
    "\n",
    "\\begin{eqnarray}\n",
    "Mx_0 \\; = \\; M(M^TM)^{-1}M^Tv_0 \\; = \\;  Q_1 \\; \\Sigma_k  \\; Q_2 Q^{T}_2 \\; \\Sigma^{-1}_k \\; Q^{T}_1 \\; v_0 \\; = \\; Q_1 \\; Q^{T}_1 \\; v_0\n",
    "\\end{eqnarray}\n",
    "\n",
    "**Remark 4.**\n",
    "As we see, $Q_1  Q^{T}_1 $ is another expression for the orthogonal projector ([6](#mjx-eqn-eq6)) onto the linear span of the columns of $M$.\n",
    "\n",
    "Let's use SVD to compute the coefficients of our *linear model* ([7](#mjx-eqn-eq7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a41c8430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 4),\n",
       " (4, 4),\n",
       " array([445.66937555,  61.29111736,   2.9703231 ,   1.01820628]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute SVD of M\n",
    "k = n_factors\n",
    "U, S, V = al.svd( M, full_matrices=False)\n",
    "U.shape, V.shape, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8d76953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.971341927085823e-13"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "N = al.norm( M - np.dot( U * S, V ) )\n",
    "N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333db3a",
   "metadata": {},
   "source": [
    "Let's recompute the linear projection using SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b4a0eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([396.12751815,  -8.22714306,   1.83551716,  57.43468942])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply formula (8)\n",
    "U_t = np.transpose( U )\n",
    "V_t = np.transpose( V )\n",
    "\n",
    "x = np.dot( V_t, (1/S) * np.dot( U_t, H ) )\n",
    "#compare that with the result obtained above\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5298dbf",
   "metadata": {},
   "source": [
    "compare this with <a href='#regresult'>linear regression result</a>) obtained above\n",
    "\n",
    "### In conclusion\n",
    "This short and rough excersise can be used as a collection of *links* to various useful topis  : \n",
    "- Linear (statistical) Models https://en.wikipedia.org/wiki/Linear_model\n",
    "- Linear Algebra https://en.wikipedia.org/wiki/Linear_algebra, in particular\n",
    "    - Vector Spaces, Matrices (https://en.wikipedia.org/wiki/Matrix_(mathematics)) and Linear Operators (https://en.wikipedia.org/wiki/Linear_map)\n",
    "    - Orthogonal Projection, Vector Norm, (Euclidean) Distance,\n",
    "        - https://en.wikipedia.org/wiki/Dot_product https://en.wikipedia.org\n",
    "        - https://en.wikipedia.org/wiki/Projection_(linear_algebra)\n",
    "        - https://en.wikipedia.org/wiki/Gram_matrix\n",
    "- SVD and other Matrix Decomposition methods https://en.wikipedia.org/wiki/Matrix_decomposition\n",
    "- Optimization https://en.wikipedia.org/wiki/Mathematical_optimization   \n",
    "- Python https://www.python.org/and and numpy https://numpy.org/\n",
    "- and, nonlinear data models https://en.wikipedia.org/wiki/Nonlinear_modelling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
